{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "    \n",
    "deployment_name='IntegrationAISearch' #This will correspond to the custom name you chose for your deployment when you deployed a model. Use a gpt-35-turbo-instruct deployment. \n",
    "    \n",
    "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "print(os.getenv(\"AZURE_OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a test completion job\n",
      "What is 1+1?\";\n",
      "            int numExpectedWords = 3;\n",
      "\n",
      "Completion(id='cmpl-9RmBVLuoxydli43nc68WtWRJRnLzB', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='?\";\\n            int numExpectedWords = 3;\\n', content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1716407105, model='gpt-35-turbo', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=6, total_tokens=16), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "# Send a completion call to generate an answer\n",
    "print('Sending a test completion job')\n",
    "start_phrase = 'What is 1+1'\n",
    "response = client.completions.create(model=deployment_name, prompt=start_phrase, max_tokens=10)\n",
    "print(start_phrase+response.choices[0].text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You're good. You're good. You're good. You're good. You're good.\n",
      "\n",
      "No, I'm not.\n",
      "\n",
      "You're fine.\n",
      "\n",
      "I'm not fine.\n",
      "\n",
      "You're not fine.\n",
      "\n",
      "I'm not okay.\n",
      "\n",
      "You're okay. You\n"
     ]
    }
   ],
   "source": [
    "# Example function to call the completion API\n",
    "def get_chat_completion(prompt):\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.7,\n",
    "        n=1\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Test the function\n",
    "prompt = \"How are you?\"\n",
    "response = get_chat_completion(prompt)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Azure OpenAI\n",
    "from langchain_openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "# Replace the deployment name with your own\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    api_version=\"2024-02-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\nHow do you catch a squirrel?\\n\\nHow?\\n\\nClimb up a tree and act like a nut. (laughing)\\n\\nAll right, that's pretty good. So you're a pretty funny guy.\\n\\nI try to be.\\n\\nSo what made you decide to come in and see us at the clinic?\\n\\nWell, I've been having some symptoms that are concerning to me. I've been having some pretty bad headaches and some neck pain. And so I thought I should come in and get it checked out.\\n\\nYeah, that's a good idea. Any other symptoms?\\n\\nYeah, I've been having some numbness and tingling in my arms and my hands. And it's been going on for a couple of weeks now.\\n\\nOkay, that definitely sounds concerning. We're gonna have to take a look into that. So let me ask you some more questions about those symptoms. So your headaches, can you describe those?\\n\\nYeah, they're pretty bad headaches. They're pretty severe. They usually start in the back of my head and then they kind of move forward. And they're usually around the side of my head and they're just pretty intense.\\n\\nOkay, and do they come and go or are they constant?\\n\\nThey come and go, but they're usually\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the LLM\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\")\\r\\n        if ans.lower() == \"2\":\\r\\n            print(\"Correct\")\\r\\n            print(\"You have earned a point\")\\r\\n            score += 1\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ2()\\r\\n        else:\\r\\n            print(\"Incorrect\")\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ2()\\r\\n\\r\\n\\r\\n    def AnsQ2():\\r\\n        global score\\r\\n        ans = input(\"Whats 2+2?\")\\r\\n        if ans.lower() == \"4\":\\r\\n            print(\"Correct\")\\r\\n            print(\"You have earned a point\")\\r\\n            score += 1\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ3()\\r\\n        else:\\r\\n            print(\"Incorrect\")\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ3()\\r\\n\\r\\n    def AnsQ3():\\r\\n        global score\\r\\n        ans = input(\"Whats 3+3?\")\\r\\n        if ans.lower() == \"6\":\\r\\n            print(\"Correct\")\\r\\n            print(\"You have earned a point\")\\r\\n            score += 1\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ4()\\r\\n        else:\\r\\n            print(\"Incorrect\")\\r\\n            print(f\"Score: {score}\")\\r\\n            AnsQ4()\\r\\n\\r\\n    def AnsQ4():\\r\\n        global score\\r\\n        ans = input(\"Whats'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Whats 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" that you know.\\n\\nYeah, I'm the kind of person that's a little bit of a country also. It's a very warm country. They have a lot of people living there. And they have a lot of different religions that are practiced in India.\\n\\nOkay, that's very good. Do you know something about the culture of India?\\n\\nI know that it's a very rich culture. They have a lot of different types of music and dance and art. And they're very colorful. The way they dress and the way they decorate their homes is very colorful.\\n\\nOkay, that's very good. Do you have any idea about the food of India?\\n\\nI know that it's very spicy and there are a lot of different types of curries that are served there. And I know that they also eat a lot of breads like naan and chapati.\\n\\nOkay, that's very good. Do you know something about the famous monument of India?\\n\\nYes, I know about the Taj Mahal in India. It's a very beautiful white marble building and it was built as a memorial for the wife of the king who built it.\\n\\nOkay, that's very good. Do you have any idea about the history of India?\\n\\nI know that India has a very rich history\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Tell me something about India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'IntegrationAISearch', 'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256}\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
